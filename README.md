<!-- =========================================================================================
                                     HEADER SECTION
     ========================================================================================= -->
<div align="center">

  <!-- Logo -->
  <img src="https://raw.githubusercontent.com/Amey-Thakur/MENG-COMPUTER-ENGINEERING/main/university-of-windsor-logo.png" alt="University of Windsor" width="400"/>

  <!-- Title -->
  # Machine Learning

  <!-- Subtitle -->
  ### ELEC 8900 Â· Semester III Â· MEng Computer Engineering

  <!-- Badges -->
  [![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](LICENSE)
  [![University](https://img.shields.io/badge/University-Windsor-005596.svg)](https://www.uwindsor.ca)
  [![Program](https://img.shields.io/badge/Program-MEng%20Computer%20Engineering-FFCE00.svg)](https://www.uwindsor.ca/engineering/)
  [![Curated by](https://img.shields.io/badge/Curated%20by-Amey%20Thakur-blue.svg)](https://github.com/Amey-Thakur)

  <!-- Short Description -->
  **A comprehensive academic archive for Machine Learning (ELEC 8900), documenting technical proficiency in supervised and unsupervised learning, neural networks, and reinforcement learning within the Master of Engineering program.**

  ---

  <!-- Navigation Links -->
  [Overview](#overview) &nbsp;Â·&nbsp; [Contents](#repository-contents) &nbsp;Â·&nbsp; [Reference Books](#reference-books) &nbsp;Â·&nbsp; [Personal Preparation](#personal-preparation) &nbsp;Â·&nbsp; [Assignments](#assignments) &nbsp;Â·&nbsp; [In-Class Presentation](#in-class-presentation) &nbsp;Â·&nbsp; [Machine Learning Project](#machine-learning-project) &nbsp;Â·&nbsp; [Lecture Notes](#lecture-notes) &nbsp;Â·&nbsp; [Syllabus](#syllabus) &nbsp;Â·&nbsp; [Usage Guidelines](#usage-guidelines) &nbsp;Â·&nbsp; [License](#license) &nbsp;Â·&nbsp; [About](#about-this-repository) &nbsp;Â·&nbsp; [Acknowledgments](#acknowledgments)

</div>

---

<!-- =========================================================================================
                                     OVERVIEW SECTION
     ========================================================================================= -->

## Overview
Machine Learning (ELEC 8900) is a specialized graduate course in the Master of Engineering (MEng) program at the University of Windsor. This course introduces machine learning, covering fundamental concepts, techniques, and algorithms. It explores supervised learning methods including linear regression, logistic regression, multiclass classification, neural networks (CNN, RNN, FNN, deep learning), and decision trees (bias-variance decomposition). The unsupervised learning section covers probabilistic models, principle component analysis, K-Means, EM algorithm, and provides an overview of reinforcement learning.

### Course Objectives
The curriculum encompasses several key machine learning domains:
- **Supervised Learning**: Mastering regression and classification techniques to predict continuous variables and categorize data.
- **Neural Networks**: Designing and training deep learning models, including CNNs and RNNs, for complex pattern recognition.
- **Unsupervised Learning**: Implementing clustering algorithms (K-Means, EM) and dimensionality reduction (PCA) for data analysis.
- **Reinforcement Learning**: Understanding the foundations of agent-based learning, Markov decision processes, and exploration-exploitation trade-offs.
- **Applied Engineering**: Applying theoretical concepts to real-world datasets through rigorous programming projects.

### Repository Purpose
This repository represents a curated collection of study materials, reference books, supplemental resources, assignment reports, course projects, and technical presentations. The primary motivation for creating and maintaining this archive is simple yet profound: **to preserve knowledge for continuous learning and future reference**.

As the field of Artificial Intelligence evolves, the fundamental principles remain the bedrock of modern engineering. This repository serves as my intellectual reference point: a resource I can return to for reviewing algorithms, refreshing theoretical concepts, and strengthening technical understanding.

**Why this repository exists:**

- **Knowledge Preservation**: To maintain organized access to comprehensive study materials beyond the classroom
- **Continuous Learning**: To support lifelong learning by enabling easy revisitation of fundamental Machine Learning principles
- **Academic Documentation**: To authentically document my learning journey through Machine Learning
- **Community Contribution**: To share these resources with students and learners who may benefit from them

> [!NOTE]
> All materials were created, compiled, and organized by me during the Fall 2023 semester as part of my MEng degree requirements.

---

<!-- =========================================================================================
                                     CONTENTS SECTION
     ========================================================================================= -->

## Repository Contents

### Reference Books
This collection includes **comprehensive reference materials** covering all major topics:

| # | Resource | Focus Area |
|:-:|:---|:---|
| 1 | [Learning From Data - Abu-Mostafa, Magdon-Ismail, Lin](Reference%20Books/Learning%20From%20Data%20-%20Abu-Mostafa%20Magdon-Ismail%20Lin.pdf) | Mathematical foundations of learning, VC dimension, and regularization. |
| 2 | [Pattern Recognition and Machine Learning - Bishop](Reference%20Books/Pattern%20Recognition%20and%20Machine%20Learning%20-%20Christopher%20Bishop.pdf) | Bayesian inference and probabilistic graphical models. |
| 3 | [The Elements of Statistical Learning - Hastie, Tibshirani, Friedman](Reference%20Books/The%20Elements%20of%20Statistical%20Learning%20-%20Trevor%20Hastie%20Robert%20Tibshirani.pdf) | Comprehensive coverage of supervised and unsupervised learning algorithms. |
| 4 | [Reinforcement Learning: An Introduction - Sutton, Barto](Reference%20Books/Reinforcement%20Learning%20An%20Introduction%20-%20Richard%20Sutton%20Andrew%20Barto.pdf) | The definitive guide to RL algorithms and theory. |
| 5 | [Information Theory, Inference, and Learning Algorithms - MacKay](Reference%20Books/Information%20Theory%20Inference%20and%20Learning%20Algorithms%20-%20David%20MacKay.pdf) | Deep dive into information theory and neural networks. |
| 6 | [Bayesian Reasoning and Machine Learning - Barber](Reference%20Books/Bayesian%20Reasoning%20and%20Machine%20Learning%20-%20David%20Barber.pdf) | Graphical models and Bayesian methods for machine learning. |

---

### Personal Preparation
Academic roadmap and administrative records for the Fall 2023 session:

| # | Resource | Description |
|:-:|:---|:---|
| 1 | [Course Syllabus](Final_GENG8900-MachineLearning-CourseSyllabus-Fall-2023.pdf) | Official course outcomes and assessment specifications |
| 2 | [MEng Class Schedule](View%20My%20Classes%20-%20Fall%202023.pdf) | Enrollment record and pedagogical timeline |
| 3 | [Announcements](Announcements.txt) | Archival log of course announcements and directives |

---


### Assignments
Verified records of practical skill acquisition and academic assessments:

| # | Assignment | Description |
| :-: | :--- | :--- |
| 1 | [Multiple Linear Regression](Assignments/Questions%20-%20Multiple%20Linear%20Regression.pdf) | Application of multiple linear regression techniques for predictive modeling. |
| 2 | [DataCamp Certifications (Combined)](datacamp/DataCamp%20Certificates%20-%20Amey%20%5B110107589%5D.pdf) | Comprehensive portfolio of all 5 completed DataCamp course certificates. |

---

### Professional Certifications
Industry-recognized certifications in Machine Learning and Data Science:

<div align="center">

<h3>Supervised Learning with scikit-learn</h3>
<i>Classification and regression algorithms using Python.</i>
<br><br>
<img src="Assignments/Amey%20Thakur%20-%20DataCamp%20Supervised%20Learning%20with%20scikit-learn.png" width="90%" alt="Supervised Learning with scikit-learn">

</div>
<br>

<div align="center">

<h3>Unsupervised Learning in Python</h3>
<i>Clustering (K-Means) and dimensionality reduction (PCA).</i>
<br><br>
<img src="Assignments/Amey%20Thakur%20-%20DataCamp%20Unsupervised%20Learning%20in%20Python.png" width="90%" alt="Unsupervised Learning in Python">

</div>
<br>

<div align="center">

<h3>Linear Classifiers in Python</h3>
<i>Logistic Regression and Support Vector Machines (SVMs).</i>
<br><br>
<img src="Assignments/Amey%20Thakur%20-%20DataCamp%20Linear%20Classifiers%20in%20Python.png" width="90%" alt="Linear Classifiers in Python">

</div>
<br>

<div align="center">

<h3>Preprocessing for Machine Learning in Python</h3>
<i>Feature engineering, scaling, and data preparation pipelines.</i>
<br><br>
<img src="Assignments/Amey%20Thakur%20-%20DataCamp%20Preprocessing%20for%20Machine%20Learning%20in%20Python.png" width="90%" alt="Preprocessing for Machine Learning in Python">

</div>
<br>

<div align="center">

<h3>Introduction to Deep Learning in Python</h3>
<i>Neural networks and deep learning architecture fundamentals.</i>
<br><br>
<img src="Assignments/Amey%20Thakur%20-%20DataCamp%20Introduction%20to%20Deep%20Learning%20in%20Python.png" width="90%" alt="Introduction to Deep Learning in Python">

</div>
<br>

---

<!-- =========================================================================================
                                     IN-CLASS PRESENTATION SECTION
     ========================================================================================= -->

## In-Class Presentation
A detailed record of the technical presentation on regression analysis delivered during the semester.

<div align="center">

  [![Topic](https://img.shields.io/badge/Topic-Multiple%20Linear%20Regression-blue.svg)](In-Class%20Presentation)
  [![Date](https://img.shields.io/badge/Date-September%2029%2C%202023-orange.svg)](In-Class%20Presentation)
  [![Authors](https://img.shields.io/badge/Authors-Amey%2C%20Jithin%2C%20Ritika-orange.svg)](In-Class%20Presentation)
  [![Status](https://img.shields.io/badge/Status-Completed-brightgreen.svg)](In-Class%20Presentation)

</div>

> [!NOTE]
> **Academic Structure**: This presentation and report explore the mathematical foundations and practical applications of Multiple Linear Regression, demonstrating the ability to analyze relationships between multiple independent variables and a dependent variable.

### Multiple Linear Regression (Group Presentation)

| # | Resource | Category | Description |
| :-: | :--- | :--- | :--- |
| 1 | [**Multiple Linear Regression.pptx**](In-Class%20Presentation/Multiple%20Linear%20Regression%20%5BAmey,%20Jithin,%20Ritika%5D.pptx) | Presentation | Technical slide deck presenting core concepts and case studies |
| 2 | [**Multiple Linear Regression.pdf**](In-Class%20Presentation/Multiple%20Linear%20Regression%20%5BAmey,%20Jithin,%20Ritika%5D.pdf) | Report | Detailed written report and statistical analysis |
| 3 | [**Multiple regression.mp4**](In-Class%20Presentation/Multiple%20regression.mp4) | Video | Recorded delivery of the group presentation |
| 4 | [**PPT Notes**](In-Class%20Presentation/PPT%20Notes.pdf) | Documentation | Supplemental technical notes for the presentation |
| 5 | [**Presentation Template**](In-Class%20Presentation/Presentations_Template.pptx) | Template | Official academic presentation structure |

---

<!-- =========================================================================================
                                     COURSE PROJECT SECTION
     ========================================================================================= -->

## Machine Learning Project

<div align="center">

### [ðŸŽ¬ Zero-Shot Video Generation](https://github.com/Amey-Thakur/ZERO-SHOT-VIDEO-GENERATION)

**Adapting Pre-trained Diffusion Models for Zero-Shot Text-to-Video Synthesis**

[![Project](https://img.shields.io/badge/Project-Zero--Shot%20Video%20Generation-blue.svg)](https://github.com/Amey-Thakur/ZERO-SHOT-VIDEO-GENERATION) [![Stack](https://img.shields.io/badge/Stack-Generative%20AI%20%7C%20Python-orange.svg)](https://www.python.org/) [![Status](https://img.shields.io/badge/Status-Completed-brightgreen.svg)](https://github.com/Amey-Thakur/ZERO-SHOT-VIDEO-GENERATION) [![YouTube](https://img.shields.io/badge/YouTube-Demonstration-red.svg?logo=youtube)](https://youtu.be/za9hId6UPoY?si=jRAU-sT2iFWbCtIH)

</div>

<div align="center">

### Authors

| <img src="https://github.com/Amey-Thakur.png" width="150" alt="Amey Thakur"><br>[**Amey Thakur**](https://github.com/Amey-Thakur)<br><br>[![ORCID](https://img.shields.io/badge/ORCID-0000--0001--5644--1575-A6CE39)](https://orcid.org/0000-0001-5644-1575) |
| :---: |

</div>

> [!IMPORTANT]
> ### ðŸ¤ðŸ» Special Acknowledgement
> *Special thanks to **Jithin Gijo Varghese** and **Ritika Agarwal** for their meaningful contributions, guidance, and support that helped shape this work.*

### Project Overview
This study investigates and implements the **Text2Video-Zero** approach, enabling the generation of temporally coherent videos from text prompts *without* the need for large-scale video model training. The implementation focuses on modifying specific **Self-Attention** mechanisms within pre-trained diffusion models to preserve identity and background consistency across frames. The final system delivers a complete end-to-end pipeline, ranging from **Tokenization** and **Embedding** to **Video Generation**, deployed via a reactive web interface.

> [!TIP]
> **Zero-Shot Synthesis** represents a transformative shift in Generative AI; it allows the creation of dynamic video content by adapting pre-existing image models rather than requiring expensive, large-scale video training. This approach makes high-fidelity motion synthesis more accessible by focusing on **temporal consistency**: ensuring that characters and backgrounds remain stable across every frame.

### Resources
| # | Milestone | Date |
| :-: | :--- | :---: |
| 1 | [**Project Proposal**](ML%20Project/Zero-Shot%20Video%20Generation%20-%20Project%20Proposal.pdf) | October 01, 2023 |
| 2 | [**Project Presentation**](ML%20Project/Zero-Shot%20Video%20Generation.pdf) | November 22, 2023 |
| 3 | [**Final Project Report**](ML%20Project/Zero-Shot%20Video%20Generation%20Project%20Report.pdf) | November 19, 2023 |
| 4 | [**Video Demonstration**](ML%20Project/Zero-Shot%20Video%20Generation.mp4) | November 19, 2023 |
| 5 | [**YouTube Demonstration**](https://youtu.be/za9hId6UPoY?si=jRAU-sT2iFWbCtIH) | November 19, 2023 |

---

<!-- =========================================================================================
                                     LECTURE NOTES SECTION
     ========================================================================================= -->

## Lecture Notes

A comprehensive archival log documenting pedagogical discourse across fourteen weeks, including weekly slides, applied research presentations, and technical resources for the Fall 2023 session.

> [!TIP]
> Machine Learning is not merely about algorithms; it is the **bridge between data and intelligent decision-making**. Every module below focuses on the critical translation from **Theoretical Models to Applied Systems**, enabling the design and verification of complex learning architectures.

| # | Week | Date | Topic/Activity | Lecture Slides |
| :-: | :---: | :---: | :--- | :---: |
| 1 | **Week 01** | September 08, 2023 | Introduction to Machine Learning | [View](Week%201%20-%20Introduction%20to%20Machine%20Learning/Week1_Introduction%20to%20ML.pdf) |
| 2 | **Week 02** | September 15, 2023 | Data and its processing in Machine Learning | [View](Week%202%20-%20Data%20in%20Machine%20Learning/Week2-Data%20and%20its%20processing.pdf) |
| 3 | **Week 03** | September 22, 2023 | Supervised Learning | [View](Week%203%20-%20Python%20and%20Supervised%20Learning/Week3-Python%20and%20Supervised%20Learning.pdf) |
| 4 | **Week 04** | September 29, 2023 | Supervised Learning (Linear Methods for Regression, Logistic Regression, Multiclass Classification)<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 5 | **Week 05** | October 06, 2023 | Decision Trees, Random Forest<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 6 | **Week 06** | October 13, 2023 | **No Classes â€“ Reading Week** | â€” |
| 7 | **Week 07** | October 20, 2023 | Neural Networks<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 8 | **Week 08** | October 27, 2023 | Neural Networks: Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 9 | **Week 09** | November 03, 2023 | Unsupervised Learning: Generative Adversarial Networks (GANs), K-means, and Expectation Maximization (EM) Algorithm<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 10 | **Week 10** | November 10, 2023 | K-means Clustering, Expectation Maximization (EM) Algorithm (Fuzzy/Spectral/Hierarchical Clustering)<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 11 | **Week 11** | November 17, 2023 | Dimensionality Reduction: Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and Reinforcement Learning (RL)<br>*[In-class Assignment Presentations](#in-class-assignment-presentations)* | â€” |
| 12 | **Week 12** | November 24, 2023 | [Machine Learning Project Presentations](ML%20Project) | â€” |
| 13 | **Week 13** | December 01, 2023 | Reinforcement Learning (RL) & Course Wrap-Up | â€” |
| 14 | **Week 14-15** | December 09-20, 2023 | **Final Exam** | â€” |




### In-Class Assignment Presentations

A granular record of peer-led technical research presentations and computational case studies conducted during the Fall 2023 session.

> [!NOTE]
> These peer-led presentations form an essential part of the course curriculum, where student-driven research bridges the gap between machine learning theory and applied computational modeling.

| # | Week | Date | Topics | Presentations |
| :-: | :---: | :---: | :--- | :---: |
| 1 | **Week 04** | September 29, 2023 | <ol><li>Gradient Descent algorithm and its variants</li><li>Multiple Linear Regression â€“ [**Amey Thakur**](In-Class%20Presentation/)<ul><li>[**V1 PPT**](In-Class%20Presentation/Multiple%20Linear%20Regression%20[Amey,%20Jithin,%20Ritika].pdf) & [**Notebook**](In-Class%20Presentation/Relationship%20between%20Hours%20Studied%20and%20Grades%20Received.ipynb)</li><li>[**Visualization**](In-Class%20Presentation/Multiple%20regression.mp4) & [**Notes**](In-Class%20Presentation/PPT%20Notes.pdf)</li></ul></li><li>Multiple Linear Regression â€“ [**Notebook**](Week%204%20-%20In-class%20Presentations/3-Linear%20Regression%20-%20Example%20(Media%20Marketing).ipynb) & [**Dataset**](Week%204%20-%20In-class%20Presentations/3-Linear%20Regression%20Example%20(Media%20Marketing).csv)</li><li>Polynomial regression</li></ol> | <ol><li>[View](Week%204%20-%20In-class%20Presentations/1-Gradient%20Descent%20Algorithm%20and%20Its%20Variants.pdf)</li><li>[View](Week%204%20-%20In-class%20Presentations/2-Multiple%20Linear%20Regression.pdf)<br>&nbsp;<br>&nbsp;</li><li>[View](Week%204%20-%20In-class%20Presentations/3-Multiple%20Linear%20Regression.pdf)</li><li>[View](Week%204%20-%20In-class%20Presentations/4-Polynomial%20Regression.pdf)</li></ol> |
| 2 | **Week 05** | October 06, 2023 | <ol><li>Logistic Regression</li><li>Decision Tree Regression</li><li>Decision Tree Regression</li><li>Random forest regression</li></ol> | <ol><li>[View](Week%205%20-%20In-class%20Presentations/1-Logistic_Regression.pdf)</li><li>[View](Week%205%20-%20In-class%20Presentations/2-Decision_Tree_Regression%20.pdf)</li><li>[View](Week%205%20-%20In-class%20Presentations/3-Decision_Tree_Regression.pdf)</li><li>[View](Week%205%20-%20In-class%20Presentations/4-Random%20Forest%20Regression.pdf)</li></ol> |
| 3 | **Week 07** | October 20, 2023 | <ol><li>Naive Bayes Classifiers</li><li>Naive Bayes Classifiers</li><li>Non-Linear Support Vector Machines</li><li>Support Vector Machines</li><li>Ensemble, Voting and Bagging Classifiers</li></ol> | <ol><li>[View](Week%207%20-%20In-class%20Presentations/1-Naive_Bayes_Classifiers.pdf)</li><li>[View](Week%207%20-%20In-class%20Presentations/2-Naive_Bayes_Classifiers.pdf)</li><li>[View](Week%207%20-%20In-class%20Presentations/3-Non-Linear_Support_Vector_Machines.pdf)</li><li>[View](Week%207%20-%20In-class%20Presentations/4-Support_Vector_Machines.pdf)</li><li>[View](Week%207%20-%20In-class%20Presentations/5-Ensemble,%20Voting%20and%20Bagging%20Classifiers.pdf)</li></ol> |
| 4 | **Week 08** | October 27, 2023 | <ol><li>Convolutional Neural Networks (CNNs)</li><li>Convolutional Neural Networks (CNNs)</li><li>Recurrent Neural Networks (RNNs)</li><li>Recurrent Neural Networks (RNNs)</li></ol> | <ol><li>[View](Week%208%20-%20In-class%20Presentations/1-Convolutional%20Neural%20Networks%20(CNNs).pdf)</li><li>[View](Week%208%20-%20In-class%20Presentations/2-Convolutional%20Neural%20Networks%20(CNNs).pdf)</li><li>[View](Week%208%20-%20In-class%20Presentations/3-Recurrent%20Neural%20Networks%20(RNNs).pdf)</li><li>[View](Week%208%20-%20In-class%20Presentations/4-Recurrent%20Neural%20Networks%20(RNNs).pdf)</li></ol> |
| 5 | **Week 09** | November 03, 2023 | <ol><li>Generative Adversarial Networks (GANs)</li><li>K-mean clustering</li><li>Expectation Maximization (EM) Algorithm</li><li>Mean-Shift Clustering</li><li>Fuzzy Clustering â€“ [**Notes**](Week%209%20-%20In-class%20Presentations/5-Fuzzy%20Clustering%20Notes.pdf)</li></ol> | <ol><li>[View](Week%209%20-%20In-class%20Presentations/1-Generative%20Adversarial%20Networks.pdf)</li><li>[View](Week%209%20-%20In-class%20Presentations/2-K-mean_Clustering.pdf)</li><li>[View](Week%209%20-%20In-class%20Presentations/3-Expectation%20Maximization.pdf)</li><li>[View](Week%209%20-%20In-class%20Presentations/4-Mean-Shift%20Clustering.pdf)</li><li>[View](Week%209%20-%20In-class%20Presentations/5-Fuzzy%20Clustering.pdf)</li></ol> |
| 6 | **Week 10** | November 10, 2023 | <ol><li>Spectral Clustering</li><li>Hierarchical Clustering</li><li>DBSCAN â€“ Density Based Clustering</li><li>Dimensionality reduction: Principle Component Analysis</li><li>Dimensionality reduction: Principle Component Analysis</li><li>Dimensionality reduction: Principle Component Analysis</li></ol> | <ol><li>[View](Week%2010%20-%20In-class%20Presentations/1-Spectral_Clustering.pdf)</li><li>[View](Week%2010%20-%20In-class%20Presentations/2-Hierarchical_Clustering.pdf)</li><li>[View](Week%2010%20-%20In-class%20Presentations/3-DBSCAN.pdf)</li><li>[View](Week%2010%20-%20In-class%20Presentations/4-Dimensionality_Reduction_PCA.pdf)</li><li>[View](Week%2010%20-%20In-class%20Presentations/5-Dimensionality_Reduction_PCA.pdf)</li><li>[View](Week%2010%20-%20In-class%20Presentations/6-Dimensionality_Reduction_PCA.pdf)</li></ol> |
| 7 | **Week 11** | November 17, 2023 | <ol><li>Dimensionality reduction: Linear Discriminant Analysis</li><li>Reinforcement Learning: Q-Learning</li><li>Reinforcement Learning: Q-Learning</li><li>Reinforcement Learning: Policy Gradient methods</li><li>Reinforcement Learning: Policy Gradient methods</li></ol> | <ol><li>[View](Week%2011%20-%20In-class%20Presentations/1-Linear%20Discriminant%20Analysis.pdf)</li><li>[View](Week%2011%20-%20In-class%20Presentations/2-Reinforcement_Learning_Q-Learning.pdf)</li><li>[View](Week%2011%20-%20In-class%20Presentations/3-Reinforcement%20Learning%20-%20Q-Learning.pdf)</li><li>[View](Week%2011%20-%20In-class%20Presentations/4-Reinforcement%20Learning_Policy%20Gradient%20methods.pdf)</li><li>[View](Week%2011%20-%20In-class%20Presentations/5-Reinforcement%20Learning%20Policy%20Gradient%20methods.pdf)</li></ol> |

---

<!-- =========================================================================================
                                     SYLLABUS SECTION
     ========================================================================================= -->

## Syllabus
> **[Official ELEC 8900 Syllabus](Final_ELEC8900-MachineLearning-CourseSyllabus-Fall-2023.pdf)**  
> Complete graduate-level syllabus document for the **Fall 2023** session, including detailed course outcomes, assessment criteria, and module specifications for Machine Learning and Pattern Recognition.

> [!IMPORTANT]
> Always verify the latest syllabus details with the official University of Windsor academic portal, as curriculum specifications for machine learning may undergo instructor-led adaptations across different sessions.

---

<!-- =========================================================================================
                                     USAGE GUIDELINES
     ========================================================================================= -->

## Usage Guidelines
This repository is openly shared to support learning and knowledge exchange across the academic community.

**For Students**  
Use these resources as templates for project proposals, reference materials for learning theory, and examples of scholarly documentation. All content is organized for self-paced learning.

**For Educators**  
These materials may serve as curriculum references, sample project benchmarks, or supplementary instructional content in machine learning. Attribution is appreciated when utilizing content.

**For Researchers**  
The project reports and architectural documentation may provide insights into machine learning methodologies and professional engineering documentation structuring.

---

<!-- =========================================================================================
                                     LICENSE SECTION
     ========================================================================================= -->

## License
This repository and all linked academic content are made available under the **Creative Commons Attribution 4.0 International License (CC BY 4.0)**. See the [LICENSE](LICENSE) file for complete terms.

> [!NOTE]
> **Summary**: You are free to share and adapt this content for any purpose, even commercially, as long as you provide appropriate attribution to the original author.

---

<!-- =========================================================================================
                                     ABOUT SECTION
     ========================================================================================= -->

## About This Repository
**Created & Maintained by**: [Amey Thakur](https://github.com/Amey-Thakur)  
**Academic Journey**: Master of Engineering in Computer Engineering (2023-2024)  
**Institution**: [University of Windsor](https://www.uwindsor.ca), Windsor, Ontario  
**Faculty**: [Faculty of Engineering](https://www.uwindsor.ca/engineering/)

This repository represents a comprehensive collection of study materials, reference books, supplemental resources, weekly lecture archives, and project reports curated during my academic journey. All content has been carefully organized and documented to serve as a valuable resource for students pursuing Machine Learning.

**Connect**: [GitHub](https://github.com/Amey-Thakur) &nbsp;Â·&nbsp; [LinkedIn](https://www.linkedin.com/in/amey-thakur) &nbsp;Â·&nbsp; [ORCID](https://orcid.org/0000-0001-5644-1575)

### Acknowledgments
Grateful acknowledgment to **Dr. Yasser M. Alginahi** for his exceptional instruction in Machine Learning, which played an important role in shaping my understanding of the subject. His clear and disciplined approach, along with his thorough explanation of complex algorithms and neural networks, made the subject both accessible and engaging. His dedication to academic excellence in the field of artificial intelligence is gratefully acknowledged.

Grateful acknowledgment to my Major Project teammates, **Jithin Gijo Varghese** and **Ritika Agarwal**, for their collaborative excellence and technical proficiency. We worked closely to implement and validate complex machine learning architectures, and their contributions were essential in transforming theoretical concepts into robust engineering solutions.

Grateful acknowledgment to **Jason Horn**, **[Writing Support Desk](https://github.com/Amey-Thakur/WRITING-SUPPORT)**, **University of Windsor**, for his distinguished mentorship and scholarly guidance. His thoughtful feedback and methodological precision were instrumental in strengthening the analytical depth and professional quality of my academic work. His commitment to excellence and integrity is gratefully acknowledged.

Special thanks to the **mentors** and **peers** whose encouragement, discussions, and support contributed meaningfully to this learning experience.

---

<!-- =========================================================================================
                                     FOOTER SECTION
     ========================================================================================= -->
<div align="center">

  <!-- Footer Navigation -->
  [â†‘ Back to Top](#machine-learning)

  [Overview](#overview) &nbsp;Â·&nbsp; [Contents](#repository-contents) &nbsp;Â·&nbsp; [Reference Books](#reference-books) &nbsp;Â·&nbsp; [Personal Preparation](#personal-preparation) &nbsp;Â·&nbsp; [Assignments](#assignments) &nbsp;Â·&nbsp; [In-Class Presentation](#in-class-presentation) &nbsp;Â·&nbsp; [Machine Learning Project](#machine-learning-project) &nbsp;Â·&nbsp; [Lecture Notes](#lecture-notes) &nbsp;Â·&nbsp; [Syllabus](#syllabus) &nbsp;Â·&nbsp; [Usage Guidelines](#usage-guidelines) &nbsp;Â·&nbsp; [License](#license) &nbsp;Â·&nbsp; [About](#about-this-repository) &nbsp;Â·&nbsp; [Acknowledgments](#acknowledgments)

</div>

---

<div align="center">

  ### ðŸŽ“ [MEng Computer Engineering Repository](https://github.com/Amey-Thakur/MENG-COMPUTER-ENGINEERING)

  **Computer Engineering (M.Eng) - University of Windsor**

  *An archival record of **graduate-level research** and **advanced engineering coursework**.*

</div>